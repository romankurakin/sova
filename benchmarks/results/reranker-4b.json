{
  "name": "reranker-4b",
  "k": 10,
  "created": "2026-02-16 23:18:13",
  "latency_ms": {
    "p50": 679.8,
    "p95": 1562.5
  },
  "metrics": {
    "mrr": {
      "1": 0.5625,
      "3": 0.7291666666666666,
      "5": 0.7291666666666666,
      "10": 0.7395833333333334
    },
    "ndcg": {
      "1": 0.625,
      "3": 0.6219352503098756,
      "5": 0.6373461350364156,
      "10": 0.7049813896218442
    },
    "map": {
      "1": 0.5625,
      "3": 0.48611111111111105,
      "5": 0.49506944444444445,
      "10": 0.5056663655045351
    },
    "precision": {
      "1": 0.5625,
      "3": 0.6041666666666666,
      "5": 0.625,
      "10": 0.6
    },
    "recall": {
      "1": 0.04915900072150072,
      "3": 0.17173653552330023,
      "5": 0.28306224004753416,
      "10": 0.5984386936592819
    },
    "hit_rate": {
      "1": 0.5625,
      "3": 0.9375,
      "5": 0.9375,
      "10": 1.0
    },
    "subtopic_recall": {
      "1": 0.05029443090321628,
      "3": 0.17571207146765555,
      "5": 0.2885904207473991,
      "10": 0.6051364464013604
    },
    "alpha_ndcg": {
      "1": 0.9285714285714286,
      "3": 0.9227534866985402,
      "5": 0.965164998468296,
      "10": 1.0792113184636634
    },
    "doc_coverage": {
      "1": 1.0,
      "3": 0.5833333333333333,
      "5": 0.4375,
      "10": 0.26875
    }
  },
  "negative_fp_rate": {
    "1": 0.0,
    "3": 0.0,
    "5": 0.0,
    "10": 0.0
  },
  "by_category": {
    "exact_lookup": {
      "mrr": 0.8333333333333334,
      "ndcg": 0.8579547235556795,
      "map": 0.5985558390022676,
      "precision": 0.6,
      "recall": 0.8125,
      "subtopic_recall": 0.8125,
      "doc_coverage": 0.15,
      "count": 4
    },
    "conceptual": {
      "mrr": 0.5833333333333334,
      "ndcg": 0.6626454613067565,
      "map": 0.48235863095238096,
      "precision": 0.625,
      "recall": 0.544485294117647,
      "subtopic_recall": 0.5529745989304813,
      "doc_coverage": 0.25,
      "count": 4
    },
    "cross_doc": {
      "mrr": 0.75,
      "ndcg": 0.5851470499405229,
      "map": 0.5954662698412698,
      "precision": 0.75,
      "recall": 0.3839285714285714,
      "subtopic_recall": 0.4050711866749602,
      "doc_coverage": 0.3,
      "count": 4
    },
    "natural": {
      "mrr": 0.7916666666666666,
      "ndcg": 0.7141783236844177,
      "map": 0.3462847222222222,
      "precision": 0.425,
      "recall": 0.6528409090909091,
      "subtopic_recall": 0.65,
      "doc_coverage": 0.375,
      "count": 4
    },
    "negative": {
      "mrr": 0.0,
      "ndcg": 0.25090167565117477,
      "map": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "subtopic_recall": 0.0,
      "doc_coverage": 0.375,
      "count": 4
    }
  },
  "auto_filled": 0,
  "unjudged": 1
}