{
  "name": "llama-server-migration",
  "k": 10,
  "created": "2026-02-16 23:04:03",
  "latency_ms": {
    "p50": 751.6,
    "p95": 1082.8
  },
  "metrics": {
    "mrr": {
      "1": 0.5625,
      "3": 0.7291666666666666,
      "5": 0.7291666666666666,
      "10": 0.7395833333333334
    },
    "ndcg": {
      "1": 0.625,
      "3": 0.6219352503098756,
      "5": 0.6373461350364156,
      "10": 0.694925956732455
    },
    "map": {
      "1": 0.5625,
      "3": 0.48611111111111105,
      "5": 0.49506944444444445,
      "10": 0.5002608595521542
    },
    "precision": {
      "1": 0.5625,
      "3": 0.6041666666666666,
      "5": 0.625,
      "10": 0.5875
    },
    "recall": {
      "1": 0.04915900072150072,
      "3": 0.17173653552330023,
      "5": 0.28306224004753416,
      "10": 0.5828136936592819
    },
    "hit_rate": {
      "1": 0.5625,
      "3": 0.9375,
      "5": 0.9375,
      "10": 1.0
    },
    "subtopic_recall": {
      "1": 0.05029443090321628,
      "3": 0.17571207146765555,
      "5": 0.2885904207473991,
      "10": 0.5914645714013604
    },
    "alpha_ndcg": {
      "1": 0.9285714285714286,
      "3": 0.9227534866985402,
      "5": 0.965164998468296,
      "10": 1.0605072151066097
    },
    "doc_coverage": {
      "1": 1.0,
      "3": 0.5833333333333333,
      "5": 0.4375,
      "10": 0.3125
    }
  },
  "negative_fp_rate": {
    "1": 0.0,
    "3": 0.0,
    "5": 0.0,
    "10": 0.0
  },
  "by_category": {
    "exact_lookup": {
      "mrr": 0.8333333333333334,
      "ndcg": 0.8579547235556795,
      "map": 0.5985558390022676,
      "precision": 0.6,
      "recall": 0.8125,
      "subtopic_recall": 0.8125,
      "doc_coverage": 0.15,
      "count": 4
    },
    "conceptual": {
      "mrr": 0.5833333333333334,
      "ndcg": 0.6630843671826627,
      "map": 0.4840252976190476,
      "precision": 0.625,
      "recall": 0.544485294117647,
      "subtopic_recall": 0.5529745989304813,
      "doc_coverage": 0.275,
      "count": 4
    },
    "cross_doc": {
      "mrr": 0.75,
      "ndcg": 0.5851470499405229,
      "map": 0.5954662698412698,
      "precision": 0.75,
      "recall": 0.3839285714285714,
      "subtopic_recall": 0.4050711866749602,
      "doc_coverage": 0.3,
      "count": 4
    },
    "natural": {
      "mrr": 0.7916666666666666,
      "ndcg": 0.6735176862509551,
      "map": 0.32299603174603175,
      "precision": 0.375,
      "recall": 0.5903409090909091,
      "subtopic_recall": 0.5953125,
      "doc_coverage": 0.525,
      "count": 4
    },
    "negative": {
      "mrr": 0.0,
      "ndcg": 0.25090167565117477,
      "map": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "subtopic_recall": 0.0,
      "doc_coverage": 0.475,
      "count": 4
    }
  },
  "auto_filled": 0,
  "unjudged": 1
}